{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b63082-e82c-4cab-8aa4-86861b26b37b",
   "metadata": {},
   "source": [
    "<img src=\"static/images/datachain-logo.png\" alt=\"Dataset\" style=\"width: 200px;\"/>\n",
    "\n",
    "# 🚀 Run Inference Jobs using Datachain (scalable batch scoring)\n",
    "\n",
    "In this tutorial, you'll learn how to run inference jobs on a large dataset using **[Datachain](https://github.com/iterative/datachain)** in batch processing. Batch inference is useful when you have a pre-trained model and want to make predictions on a dataset without needing real-time processing. **[Datachain](https://github.com/iterative/datachain)** provides a convenient way to run inference jobs on datasets stored in DataChain.\n",
    "\n",
    "## 📋  Agenda\n",
    "\n",
    "1. Load Pre-trained Model\n",
    "2. Define Inference Classes\n",
    "3. Run Inference\n",
    "4. Save Predictions\n",
    "\n",
    "## 🛠 Prerequisites\n",
    "\n",
    "Before you begin, ensure you have:\n",
    "\n",
    "- **[Datachain](https://github.com/iterative/datachain)** installed in your environment. \n",
    "- The necessary dependencies installed, including PyTorch and the required libraries.\n",
    "- Access to the pre-trained model file `model.pth`.\n",
    "- Access to the test dataset `fashion-test` for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60ae41-e1fe-411e-a424-688360bf4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from datachain import C, DataChain, DataModel\n",
    "from datachain.lib.image import convert_image\n",
    "from torch import optim\n",
    "\n",
    "from src.train import CNN, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04beb1e6-e8b6-4113-856e-0aeca2e1b55d",
   "metadata": {},
   "source": [
    "# 📥 Load Model (pre-trained)\n",
    "\n",
    "- Load the pre-trained model weights and optimizer state.\n",
    "- Create an instance of the `CNN` model.\n",
    "- Create an optimizer using `optim.SGD`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a0f20-b6eb-436d-be01-f1b864d78ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Load Pre-trained Model  #####\n",
    "\n",
    "checkpoint = torch.load(\"model.pth\")\n",
    "CLASSES = checkpoint[\"classes\"]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "model = CNN(NUM_CLASSES)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "print(CLASSES)\n",
    "print(NUM_CLASSES)\n",
    "print(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d682ce-7655-4364-8c22-f0120c8f88d7",
   "metadata": {},
   "source": [
    "By following these steps, you can easily load a pre-trained model and its associated optimizer state in PyTorch. This allows you to leverage the learned weights and continue training or perform inference without starting from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff9fe1-8f86-4e00-b0d6-6c72d7998e9a",
   "metadata": {},
   "source": [
    "# ✅ Run Inference & Save Predictions\n",
    "\n",
    "- Load the `fashion-test` dataset.\n",
    "- Apply filters to select only 'Coffee' category images with non-empty `front_back` values.\n",
    "- Use `map()` to apply the `InferenceMapper` to each image in the dataset.\n",
    "- The `InferenceMapper` takes the image binary file as input and outputs the predicted class, probability, and label.\n",
    "- The `save()` method is used to save the dataset with the predicted values as `fashion-predictions`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e7eb3-7cf5-4d65-b023-994b2cb0ccde",
   "metadata": {},
   "source": [
    "## Define the inference classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25770553-2e97-4d84-894a-748edddbbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inference #####\n",
    "\n",
    "class Predictions(DataModel):\n",
    "    pred_class: int\n",
    "    pred_proba: float\n",
    "    pred_label: str\n",
    "\n",
    "class InferenceMapper():\n",
    "\n",
    "    def __init__(self, model, classes):\n",
    "        self.model = model\n",
    "        self.classes = classes \n",
    "        \n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, file) -> Predictions:\n",
    "\n",
    "        img_raw = file.read()\n",
    "        img = convert_image(img_raw, transform=transform).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # emb = model(img)\n",
    "            outputs = self.model(img)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence, predicted_classes = torch.max(probs, 1)\n",
    "\n",
    "        return Predictions(\n",
    "            pred_class=predicted_classes.item(),\n",
    "            pred_proba=confidence.item(),\n",
    "            pred_label=self.classes[predicted_classes.item()]\n",
    "        )\n",
    "\n",
    "inference_eng = InferenceMapper(model, CLASSES) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0076f-7b51-4faa-a82e-d91104bb6fac",
   "metadata": {},
   "source": [
    "- Define a `Predictions` class that inherits from `DataModel` to store the predicted class, probability, and label.\n",
    "- Define an `InferenceMapper` class to perform the inference logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c13761-c56a-4a51-b393-904df5c86547",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4a5b5-b013-4055-9a53-8074c27d30eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    DataChain.from_dataset(\"fashion-test\")\n",
    "    .settings(parallel=-1)    \n",
    "    .map(predictions=lambda file: inference_eng.predict(file), output=Predictions)\n",
    "    .save(\"fashion-predictions\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1afd36-08e4-423c-a8a2-2b12ff1a1f01",
   "metadata": {},
   "source": [
    "## Explore predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ab28a-f25b-4c11-b595-8f37662677d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataChain.from_dataset(\"fashion-predictions\").select(\"predictions\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af7fd3-9d4c-430d-b033-20916f538396",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataChain.from_dataset(\"fashion-predictions\").to_pandas().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608ca80-9e7a-4a0a-b0f2-eeaad5bbfd14",
   "metadata": {},
   "source": [
    "## Delta Updates \n",
    "\n",
    "- Assume we already calculated predictions for 'old' dataset (for this example assume it's all images added before 2017)\n",
    "- The 'new' dataset contains some images added after 2017\n",
    "- We want to calculate inference for this delta updates only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5b0fc-e08a-4fac-8c62-02f78b0755aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "\n",
    "old = (\n",
    "    DataChain.from_dataset(\"fashion-product-images\")\n",
    "    .filter(C(\"masterCategory\") == \"Apparel\" and C(\"subCategory\") == \"Topwear\")\n",
    "    .filter(C(\"year\") < 2017)\n",
    "    # .limit(3)\n",
    ")\n",
    "print(old.to_pandas().shape)\n",
    "\n",
    "new = (\n",
    "    DataChain.from_dataset(\"fashion-product-images\")\n",
    "    .filter(C(\"masterCategory\") == \"Apparel\" and C(\"subCategory\") == \"Topwear\")\n",
    ")\n",
    "print(new.to_pandas().shape)\n",
    "\n",
    "update = new.subtract(old)\n",
    "print(update.to_pandas().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a9725-a501-4bdc-be10-f9cd9595a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_predictions = (\n",
    "    update\n",
    "    .map(predictions=lambda file: inference_eng.predict(file), output=Predictions)\n",
    ")\n",
    "\n",
    "df = update_predictions.to_pandas()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc6c02-f66c-4508-90b5-4250dd1c9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of Predictions before the union (old)\n",
    "\n",
    "DataChain.from_dataset(\"fashion-predictions\").to_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526a943-2a14-46a5-bca5-47a3ac9197b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add (union) new predictions and save (as a new version)\n",
    "\n",
    "(\n",
    "    DataChain.from_dataset(\"fashion-predictions\")\n",
    "    .union(update_predictions)\n",
    "    .save(\"fashion-predictions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77931a12-caeb-4ba5-99f6-a263bf5878f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of Predictions after union\n",
    "\n",
    "DataChain.from_dataset(\"fashion-predictions\").to_pandas().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d607b76-b5c0-40de-b4e4-a2a2d42e08ca",
   "metadata": {},
   "source": [
    "# 🔍 Analyze Predictions\n",
    "\n",
    "After running inference on your test dataset and generating predictions, it's crucial to analyze the results to gain insights into your model's performance. \n",
    "\n",
    "DataChain provides powerful tools to filter and examine the predictions, allowing you to identify correct predictions, incorrect predictions, and explore different confidence levels. Let's break down the code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6d3f7-2488-40ce-ae3f-74f0f5e053cf",
   "metadata": {},
   "source": [
    "## Show correct predictions\n",
    "\n",
    "- Load the \"fashion-predictions\" dataset, which contains the predicted labels and probabilities along with the ground truth labels.\n",
    "- Filter the dataset to include only the correct predictions where the predicted label (`pred_label`) matches the ground truth label (`usage`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a335c11-9107-4033-8e2c-a2d669cd9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show correct predictions\n",
    "\n",
    "(\n",
    "    DataChain.from_dataset(\"fashion-predictions\")\n",
    "    .filter(C(\"usage\") == C(\"predictions\").pred_label)\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2120e2-79c7-4ab5-809e-8098ba5c25fe",
   "metadata": {},
   "source": [
    "## Show incorrect predictions\n",
    "\n",
    "- Filter the dataset to include only the incorrect predictions where the predicted label (`pred_label`) does not match the ground truth label (`usage`).\n",
    "- Assign the filtered dataset to the variable `mistakes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de065f3b-8a3d-4201-9023-be17178b30f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show incorrect predictions\n",
    "\n",
    "mistakes = (\n",
    "    DataChain.from_dataset(\"fashion-predictions\")\n",
    "    .filter(C(\"usage\") != C(\"predictions\").pred_label)\n",
    "    .select(\"file\", \"usage\", \"predictions\")\n",
    ")\n",
    "mistakes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ec25e-b492-4e2f-a0d0-183506f46f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mistakes.to_pandas()\n",
    "print(df.shape)\n",
    "\n",
    "df[\"predictions.pred_proba\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783a6a3-e302-4be6-b4a3-09350732224a",
   "metadata": {},
   "source": [
    "## Analyze high-confidence and low-confidence mistakes\n",
    "\n",
    "- Filter the `mistakes` dataset\n",
    "    -  `high-confidence` are mistakes where the predicted probability (`pred_proba`) is more than 0.5.\n",
    "    -  `low-confidence` are mistakes where the predicted probability (`pred_proba`) is less than 0.5.\n",
    "- Order the filtered dataset by the predicted probability in ascending order using `order_by(C(\"pred_proba\").asc())`.\n",
    "- Convert the filtered and ordered dataset to a pandas DataFrame using `to_pandas()`.\n",
    "- Print the shape of the resulting DataFrame to see the number of low-confidence mistakes.\n",
    "- Display the first 3 low-confidence mistakes using `head(3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76f16d-c2e6-47a9-806b-5355547f1e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find high-confidence mistakes\n",
    "\n",
    "high_conf_mist =(\n",
    "    mistakes\n",
    "    .filter(C(\"predictions.pred_proba\") > 0.85 )\n",
    "    .order_by(C(\"predictions.pred_proba\").desc())\n",
    ")\n",
    "\n",
    "print(high_conf_mist.to_pandas().shape)\n",
    "high_conf_mist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23887a00-7700-42ec-8454-98dc2a721379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find low-confidence mistakes\n",
    "\n",
    "low_conf_mist = (\n",
    "    mistakes\n",
    "    .filter(C(\"predictions.pred_proba\") < 0.5 )\n",
    "    .order_by(C(\"predictions.pred_proba\").asc())\n",
    ")\n",
    "\n",
    "print(low_conf_mist.to_pandas().shape)\n",
    "low_conf_mist.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5996c-5fe0-4142-97ee-6489ef0c770e",
   "metadata": {},
   "source": [
    "# 📊 Visualize mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897c56a-e8b6-498b-a499-96be6f2d72a6",
   "metadata": {},
   "source": [
    "We can use `DataChain.collect()` to extract the values from the sample. Here's an example of collecting a subset of column signals from the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c80b1-0545-4688-82bb-dacb4b2d9ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_results = list(high_conf_mist.collect())\n",
    "sample_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6668770-e17b-4a3a-b358-7eeb247ceca5",
   "metadata": {},
   "source": [
    "The example has an output for each signal:\n",
    "- `file` returns a special `ImageFile` object (see below).\n",
    "- `usage` returns an original target class name\n",
    "- `predictions` returns prediction data fields. \n",
    "\n",
    "DataChain knows to treat `file` as an `ImageFile` because we created the chain for the image files with `DataChain.from_storage(..., type=\"image\")`. `ImageFile` is a \"DataModel\" in Datachain, and you can use `.read()` to get its value, which for `ImageFile` returns the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850ab6c-12e7-4953-a25c-59d785021b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = sample_results[0]\n",
    "example[0].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d4dd5-c3eb-4119-8b5f-173bded92e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare utility function to display sample results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def display_image_matrix(items, top):\n",
    "    # Constants for the layout\n",
    "    columns = 5\n",
    "    rows = int(np.ceil(top / columns))\n",
    "\n",
    "    # Create subplots\n",
    "    fig, ax_arr = plt.subplots(rows, columns, figsize=(15, 3 * rows))\n",
    "    fig.suptitle(\"Displaying images\", fontsize=20)\n",
    "    ax_arr = ax_arr.flatten() # Flatten the array of axes, in case of a single row\n",
    "\n",
    "    # Plot images\n",
    "    for i in range(top):\n",
    "        if i < len(items):  # Check to avoid index error if less items than top\n",
    "            img = items[i][0].read()  # Retrieve the image\n",
    "            true_class = items[i][1]\n",
    "            preds = items[i][2].model_dump()\n",
    "            pred_class = preds['pred_label']\n",
    "\n",
    "            # Set image and title\n",
    "            ax_arr[i].imshow(img)\n",
    "            ax_arr[i].set_title(f\"True: {true_class}\\nPred: {pred_class}\", fontsize=14, backgroundcolor='white')\n",
    "            ax_arr[i].axis('off')  # Hide axes\n",
    "        else:\n",
    "            ax_arr[i].axis('off')  # Hide unused subplots\n",
    "\n",
    "    # Adjust layout and padding\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb433e7-8693-439b-8bfd-cc9b3bbfc23e",
   "metadata": {},
   "source": [
    "## Explore Low Confidence Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a89187-3a38-4163-b7a5-2b81af57425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low Confidence Mistakes\n",
    "\n",
    "TOP = 10\n",
    "# for item in low_conf_mist.limit(TOP).collect():\n",
    "#     display(item[0].read())\n",
    "    \n",
    "items = list(low_conf_mist.limit(TOP).collect())\n",
    "display_image_matrix(items, TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebffca29-4b75-4618-b1a5-1b07756f629e",
   "metadata": {},
   "source": [
    "## Explore High Confidence Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1eb2f-5688-4b68-9868-07f4b0500c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How Confidence Mistakes\n",
    "\n",
    "TOP = 10\n",
    "# for item in high_conf_mist.limit(TOP).collect():\n",
    "#     display(item[0].read())\n",
    "\n",
    "items = list(high_conf_mist.limit(TOP).collect())\n",
    "display_image_matrix(items, TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea32cb-6b77-41fc-9cce-47051b5c35e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:12:28.967488Z",
     "iopub.status.busy": "2024-05-16T15:12:28.967022Z",
     "iopub.status.idle": "2024-05-16T15:12:29.010466Z",
     "shell.execute_reply": "2024-05-16T15:12:29.009924Z",
     "shell.execute_reply.started": "2024-05-16T15:12:28.967461Z"
    }
   },
   "source": [
    "## Explore Correct Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e66918-d677-4d81-8467-848b7db8ea7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_preds = (\n",
    "    DataChain.from_dataset(\"fashion-predictions\")\n",
    "    .filter(C(\"usage\") == C(\"predictions.pred_label\"))\n",
    "    .order_by(C(\"predictions.pred_proba\").desc())\n",
    "    .select(\"file\", \"usage\", \"predictions\")\n",
    ")\n",
    "\n",
    "print(correct_preds.to_pandas().shape)\n",
    "correct_preds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93461d5e-09ab-47ea-8ef3-ad025b073766",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP = 10\n",
    "# for item in high_conf_mist.limit(TOP).collect():\n",
    "#     display(item[0].read())\n",
    "\n",
    "items = list(correct_preds.limit(TOP).collect())\n",
    "display_image_matrix(items, TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32badabe-b663-48e9-8204-ddcd739a974e",
   "metadata": {},
   "source": [
    "# ☁️ Run in Studio (SaaS)\n",
    "\n",
    "<a href=\"https://datachain.ai/\">\n",
    "    <img src=\"static/images/studio.png\" alt=\"DataChain Studio SaaS\" style=\"width: 600px;\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7560bd-fca4-4ad3-9e83-f3e642b3121d",
   "metadata": {},
   "source": [
    "To run these examples in Studio, follow the guide.\n",
    "\n",
    "1. Open Studio / YOUR_TEAM / `datasets` workspace\n",
    "2. Create a new Python Script\n",
    "3. Copy/paste scripts from this Jupyter Notebook\n",
    "4. Specify Settings:\n",
    "   - Computer vision dependencies\n",
    "   - pre-trained model `model.pth`\n",
    "   - import `train.py` module\n",
    "5. Click the Run button\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3306cf-a401-4ca4-a9a3-3b97be3b3c12",
   "metadata": {},
   "source": [
    "# 🎉 Summary \n",
    "\n",
    "**🌟 Congratulations! You've Successfully Completed the Inference Jobs with DataChain Tutorial! 🌟**\n",
    "\n",
    "In this tutorial, you've gained a wealth of knowledge and skills that will elevate your computer vision projects to new heights. Let's recap the key topics covered:\n",
    "\n",
    "1. 🔍 **Running Inference:** You unleashed the power of your model to make predictions on real-world fashion images.\n",
    "2. 📊 **Saving Predictions:** You discovered how to save model predictions, probabilities, and true labels into a DataChain dataset for further analysis.\n",
    "3. 🔍 **Analyzing Predictions:** You explored DataChain's querying and filtering capabilities to identify correct predictions, high-confidence mistakes, and low-confidence mistakes, gaining valuable insights into your model's performance.\n",
    "\n",
    "\n",
    "Once again, congratulations on your incredible achievement! \n",
    "\n",
    "## What's Next?\n",
    "\n",
    "Keep exploring, experimenting, and pushing the boundaries of what's possible in computer vision.  Check out the next parts of our tutorial series:\n",
    "- 📚 Check other tutorials and User Guides\n",
    "- 🔍 Try DataChain on your projects\n",
    "\n",
    "By mastering these techniques, you'll be well on your way to building powerful and efficient computer vision pipelines with DataChain.\n",
    "\n",
    "## Get Involved\n",
    "\n",
    "We'd love to have you join our growing community of DataChain users and contributors! Here's how you can get involved:\n",
    "- ⭐ Give us a star on [GitHub](https://github.com/iterative/datachain) to show your support\n",
    "- 🌐 Visit the [datachain.ai website](https://datachain.ai/) to learn more about our products and services\n",
    "- 📞 Contact us to discuss how DataChain can help streamline your company's ML workflows\n",
    "- 🙌 Follow us on social media for the latest updates and insights\n",
    "\n",
    "Thanks for choosing DataChain, and happy coding! 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420dca6-04a4-4e2b-943e-ce5f01a5c703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
